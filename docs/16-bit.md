# ANE 是 16 位的吗？

看起来是的。

当你在 CPU 上运行 Core ML 模型时，它使用 float32 进行所有计算和存储中间张量。（从 iOS 14 和 macOS 11 开始，Core ML 也可以在 CPU 上使用 float16。）

在 GPU 上，它使用 float16 存储权重和中间张量，但使用 float32 进行计算。你可以通过`MLModelConfiguration`中的`allowLowPrecisionAccumulationOnGPU`选项关闭这一功能，这样 GPU 也会使用 float16 进行计算。这样会快一点，但你可能会失去精度。

ANE 似乎对所有内容都使用 float16。这意味着如果你的模型有相对较大（`> 1e2`）或相对较小（`< 1e-4`）的激活值，你将失去精度。更糟糕的是，模型可能根本无法正确工作——即非常小的数字变为 0。

## 多精度

苹果声称 A12 Bionic 中的 ANE 支持"多精度"。这也被称为可变精度。

待办事项：研究这实际上意味着什么。

## 量化操作

Core ML 支持使用 8 位或更小的整数量化权重。然而，这似乎只是为了在 mlmodel 文件中存储权重。理论上，NPU 可以直接用量化权重执行卷积等操作，但没有证据表明 ANE 目前这样做。

从 iOS 14 和 macOS 11 开始，Core ML 确实支持 8 位操作，但仅适用于矩阵乘法层，不适用于卷积层或其他操作。目前不知道这些 8 位操作是实际在 ANE 上执行，还是仅在 CPU 上执行。
